# LibreChat MCP Servers

ThÆ° má»¥c nÃ y chá»©a cÃ¡c MCP (Model Context Protocol) servers tÃ¹y chá»‰nh cho LibreChat. Má»—i MCP server cung cáº¥p cÃ¡c cÃ´ng cá»¥ vÃ  kháº£ nÄƒng Ä‘áº·c biá»‡t Ä‘á»ƒ má»Ÿ rá»™ng tÃ­nh nÄƒng cá»§a LibreChat.

## ğŸ“ Available MCP Servers

### ğŸ”¬ Research AI Agent

**Folder**: `research-ai-agent/`  
**Transport**: SSE (Server-Sent Events)  
**Port**: 8000

Multi-agent system sá»­ dá»¥ng LangGraph Ä‘á»ƒ thá»±c hiá»‡n nghiÃªn cá»©u chuyÃªn sÃ¢u:

- **Research Agent**: TÃ¬m kiáº¿m vÃ  thu tháº­p thÃ´ng tin
- **Analysis Agent**: PhÃ¢n tÃ­ch dá»¯ liá»‡u vÃ  tÃ¬m patterns  
- **Synthesis Agent**: Tá»•ng há»£p vÃ  táº¡o bÃ¡o cÃ¡o chuyÃªn nghiá»‡p

**Tools:**
- `research_comprehensive`: NghiÃªn cá»©u Ä‘áº§y Ä‘á»§ vá»›i multi-agent pipeline
- `research_quick`: TÃ¬m kiáº¿m nhanh vá»›i single agent

**Features:**
- âœ… Docker support
- âœ… SSE transport cho Docker environments
- âœ… Health monitoring
- âœ… Professional report generation
- âœ… Supports OpenAI & Anthropic models

---

### ğŸ”„ Human in the Loop Agent

**Folder**: `human-in-loop-agent/`  
**Transport**: stdio (Standard I/O)  
**Dependencies**: Python stdlib only

Human-in-the-Loop workflows demonstrating AI workflows with human approval checkpoints:

- **Content Approval**: AI generates content â†’ Human reviews â†’ Approve/Edit/Reject
- **Task Planning**: AI creates plans â†’ Human approves â†’ Execute with modifications
- **Document Review**: AI analyzes docs â†’ Human verifies â†’ Final reviewed output

**Tools:**
- `start_content_approval`: Begin content generation workflow with human review
- `start_task_planning`: Start task breakdown workflow with human approval  
- `start_document_review`: Initiate document analysis with human verification
- `resume_workflow`: Continue paused workflow with human feedback
- `get_workflow_status`: Check status of running workflows
- `list_active_workflows`: Show all workflows awaiting human input

**Features:**
- âœ… Human approval gates at critical decision points
- âœ… Multi-stage workflow management
- âœ… State persistence during pauses
- âœ… Concurrent workflow support
- âœ… Simplified implementation (no external dependencies)
- âœ… Production-ready for LibreChat integration

**HIL Patterns Demonstrated:**
- ğŸ”„ Interrupt & Resume: Pause workflows for human input
- ğŸ‘¥ Approval Gates: Critical decisions require human oversight
- âœï¸ Iterative Editing: Human feedback improves AI output
- ğŸ“Š Workflow Management: Track and manage multiple HIL processes

---

## ğŸš€ Quick Start

### Option 1: Docker (Recommended)

```bash
cd mcps/research-ai-agent
./run_sse_server.sh docker
```

### Option 2: Local Development

```bash
cd mcps/research-ai-agent  
./run_sse_server.sh
```

## ğŸ”§ LibreChat Configuration

ThÃªm vÃ o `librechat.yaml`:

```yaml
mcpServers:
  research_ai_agent:
    type: sse
    url: http://host.docker.internal:8000/sse  # Docker Desktop
    # url: http://172.17.0.1:8000/sse         # Linux Docker
    # url: http://localhost:8000/sse          # Local
    timeout: 300000

endpoints:
  agents:
    capabilities: ["execute_code", "file_search", "actions", "tools"]
    recursionLimit: 50
```

## ğŸ“‹ Development Guidelines

### Táº¡o MCP Server má»›i

1. **Táº¡o folder má»›i**: `mcps/your-server-name/`
2. **Required files**:
   ```
   your-server-name/
   â”œâ”€â”€ main.py              # Core MCP server
   â”œâ”€â”€ requirements.txt     # Dependencies
   â”œâ”€â”€ README.md           # Documentation
   â”œâ”€â”€ Dockerfile          # For Docker support
   â”œâ”€â”€ docker-compose.yml  # Docker orchestration
   â”œâ”€â”€ env.example         # Environment template
   â””â”€â”€ test_server.py      # Testing script
   ```

3. **Transport support**:
   - **SSE**: Recommended cho Docker environments
   - **stdio**: For simple local development
   - **Both**: Maximum compatibility

4. **Health monitoring**:
   ```python
   @app.get("/health")
   async def health_check():
       return {"status": "healthy", "tools_count": len(tools)}
   ```

### Best Practices

- ğŸ³ **Docker First**: Design cho Docker deployment
- ğŸ” **Health Checks**: Implement health endpoints
- ğŸ“ **Documentation**: Comprehensive README vá»›i examples
- ğŸ§ª **Testing**: Include test scripts
- ğŸ”’ **Security**: Use environment variables cho sensitive data
- ğŸ“Š **Logging**: Implement proper logging vá»›i levels
- âš¡ **Performance**: Optimize cho production use

### Standard File Structure

```
mcps/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ server-name-1/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ env.example
â”‚   â””â”€â”€ test_server.py
â””â”€â”€ server-name-2/
    â”œâ”€â”€ main.py
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ ...
```

## ğŸ”— Useful Resources

- **MCP Specification**: https://modelcontextprotocol.io/
- **LibreChat Docs**: https://www.librechat.ai/docs/
- **LangGraph Docs**: https://langchain-ai.github.io/langgraph/
- **FastAPI Docs**: https://fastapi.tiangolo.com/

## ğŸ¤ Contributing

1. Fork repository
2. Create MCP server trong `mcps/` folder
3. Follow development guidelines
4. Submit pull request vá»›i clear description
5. Include tests vÃ  documentation

---

**Happy Building! ğŸ”§ğŸ¤–**
